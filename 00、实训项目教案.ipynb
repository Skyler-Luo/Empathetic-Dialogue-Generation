{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于 Transformer 的智能对话系统构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 课时安排\n",
    "\n",
    "**总学时：** 1 学时"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 教学课型\n",
    "\n",
    "- 理论课 [√]\n",
    "- 实验课 [√]\n",
    "- 习题课 [ ]\n",
    "- 实习课 [ ]\n",
    "- 其它 [ ]\n",
    "\n",
    "说明：本实训强调理论与实践相结合，原理讲授与代码使用穿插，确保学生在理解算法原理的同时完成从模型搭建到推理演示的全流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 题目\n",
    "\n",
    "- 基于 Transformer 的智能对话系统构建\n",
    "- 包含：数据分析与预处理、算法原理讲解、模型结构拆解、模型训练与评估、交互式推理演示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 教学重点、难点\n",
    "\n",
    "**教学重点**：\n",
    "- 了解项目背景和应用场景，理解共情对话概念。\n",
    "- 了解数据集 EmpatheticDialogues 的特点和挑战，学会分析和处理数据。\n",
    "- 学习 Transformer 的核心组件以及相关算法原理（如自注意力、多头注意力、位置编码等）。\n",
    "- 通过显式情感信息引导，探索如何在 Transformer 的基础上搭建一个具有共情对话能力的模型。\n",
    "- 基础模型的改进：多分辨率情感建模与交互式对抗训练的结合。\n",
    "- 如何评估一个对话模型的能力，了解相关指标。\n",
    "- 调用代码脚本，跑通模型训练、测试、使用的流程，增强项目开发能力。\n",
    "\n",
    "**教学难点**：\n",
    "- 掌握 Transformer 的核心组件的算法知识，以及搭建一个完整的 Transformer 对话模型。\n",
    "- 理解多分辨率情感建模的算法原理，掌握核心组件的代码。\n",
    "- 学习对抗训练相关基础知识，了解本项目中交互式对抗训练的原理，理解模型如何协同优化。\n",
    "- 掌握模型从训练到测试、评估，再到使用的完整流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 教学方法\n",
    "\n",
    "**教学方式**：\n",
    "- 算法理论教授 + 核心代码解读 + 项目上手实践 + 额外资料补充\n",
    "\n",
    "**教学手段**：\n",
    "- 白板勾画与重点知识讲解\n",
    "- 算法原理、模型结构图、核心代码互补演示\n",
    "- Notebook 实操步骤分解（环境、数据、训练、评估、推理）\n",
    "- 可视化：TensorBoard 监控 `results/tb_results/` 下 loss、ppl、acc、lr 等标量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 预期学习成果\n",
    "\n",
    "完成后，学生应能：\n",
    "- 理解并复述 EmpatheticDialogues 数据集构成与对话同理心建模难点。\n",
    "- 理清 Transformer 生成模型关键部件及推理解码策略。\n",
    "- 解释 EmpDG 的核心设计（生成器、判别器、情绪/情境融合）与训练目标。\n",
    "- 独立完成环境搭建、数据准备、基础训练与指标评估。\n",
    "- 运行脚本完成交互式对话。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 教学过程\n",
    "\n",
    "### 模块1：项目概述、环境准备、数据分析与处理\n",
    "- 内容：任务定义（同理心对话）、关键脚本与数据、EmpatheticDialogues数据集、`NRCDict.json` 情感词典\n",
    "- 要点：\n",
    "  - 创建并激活 python（≥3.8） 环境，安装 `requirements.txt`\n",
    "  - 检查 GPU：`utils/check_torch_gpu.py`\n",
    "  - 下载/准备数据：`utils/dataset_download.py` 或使用已提供 `./datasets/*`\n",
    "  - 讲解 `vectors/` 预训练词向量（GloVe）用途\n",
    "  - 对EmpatheticDialogues数据集进行详细数据分析，并进行预处理\n",
    "\n",
    "### 模块2：预备知识回顾\n",
    "- 内容：\n",
    "  - Transformer 编码-解码基本结构与自注意力；位置编码；多头注意力\n",
    "  - 训练细节：交叉熵/标签平滑、Teacher Forcing、学习率调度\n",
    "- 要点：\n",
    "  - 以 `Model/transformer.py` 为主线梳理模块接口\n",
    "  - 结合图文和代码对算法原理进行深入分析\n",
    "\n",
    "### 模块3：基础模型搭建与跑通\n",
    "- 内容：阅读 `train.py`/`run_train.py` 的参数与训练要点；`Model/common_layer.py` 的通用层；`Model/EmoPrepend.py`的完整模型实现\n",
    "- 要点：\n",
    "  - 以基础共情对话模型 EmoPrepend 为例，讲解“情感引导”对话生成实现\n",
    "  - 实例化模型熟悉模型结构，以及相关超参数模板（batch_size、max_len、embed_dim、n_heads、n_layers、dropout、lr 等）\n",
    "\n",
    "### 模块4：同理心对话的进阶与对抗训练\n",
    "- 内容：对抗训练基础知识、EmpDG 设计拆解：`Model/EmpDG_G.py`（生成器）、`Model/EmpDG_D.py`（判别器）\n",
    "- 要点：\n",
    "  - WGAN-GP相比传统 GAN 的优势\n",
    "  - 多分辨率情感建模原理，如何联合考虑粗粒度对话级情绪和细粒度 token 级情绪来生成回复\n",
    "  - 理解本模型中利用双判别器架构的交互式对抗训练\n",
    "\n",
    "### 模块5：训练、评估与可视化\n",
    "- 内容：统一训练流程；最优模型保存与测试、评估；TensorBoard 可视化\n",
    "- 要点：\n",
    "  - 跑通各模型训练流程\n",
    "  - 掌握生成式对话模型的评估指标\n",
    "\n",
    "### 模块6：推理与交互\n",
    "- 内容：使用 `interact.py` 进行多轮对话，演示同理心回应\n",
    "- 要点：\n",
    "  - 指定权重与词表，进行命令行交互"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. 环境与资源清单\n",
    "\n",
    "- 推荐环境：Python 3.8/3.9，CUDA 对应版本的 PyTorch（版本以 `requirements.txt` 为准）\n",
    "- 关键依赖：`torch`、`numpy`、`tqdm`、`tensorboard`、`nltk` 等\n",
    "- 数据资源：`datasets/empathetic-dialogue/`（含 `train/valid/test.csv`、`NRCDict.json`、缓存 numpy 文件）\n",
    "- 词向量：`vectors/glove.6B.{50,100,200,300}d.txt`\n",
    "- 日志与模型保存：`results/tb_results/`（过程日志）与 `result/`（最优权重 tar）\n",
    "- 预测与指标：`Predictions/`（输出样例、`metrics_func.py`、`models_result.json`）\n",
    "- 模型代码：`Model/`（`transformer.py`、`EmpDG_G.py`、`EmpDG_D.py`、`EmoPrepend.py`、`common_layer.py`）\n",
    "- 工具：`utils/`（`config.py`、`data_loader.py`、`data_reader.py`、`get_ed_data.py`、`dataset_download.py`）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 参考资料与延伸阅读\n",
    "\n",
    "- Attention Is All You Need：https://arxiv.org/pdf/1706.03762\n",
    "- Wasserstein GAN：https://arxiv.org/pdf/1701.07875\n",
    "- Understanding emotions in text using deep learning and big data：https://www.sciencedirect.com/science/article/abs/pii/S0747563218306150\n",
    "- Learning from Dialogue after Deployment: Feed Yourself, Chatbot!：https://arxiv.org/pdf/1901.05415\n",
    "- Long short-term memory：https://ieeexplore.ieee.org/abstract/document/6795963\n",
    "- Towards empathetic open-domain conversation models: A new benchmark and dataset：https://arxiv.org/pdf/1811.00207\n",
    "- EmpDG:Multi-resolution Interactive Empathetic Dialogue Generation：https://arxiv.org/pdf/1911.08698\n",
    "- Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory：https://arxiv.org/pdf/1704.01074"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "empdg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
